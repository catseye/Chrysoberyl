# encoding: UTF-8
# this one's a real grab-bag, for now
Comment:
  type: Language Construct
  description: |
    A comment is a part of a program that isn't part of the program.
  commentary: |
    Don't comment *who* or *when*. That's the source control system's job.
    
    Don't comment *what*. If I'm a programmer worth my salt, I can read your
    code and figure out the *what*.
    
    Don't spend a lot of space commenting *how*. Just provide a reference,
    like "Implements topological sort (see CLR)". If I'm an engineer worth
    my salt, I can look it up if I'm not already familiar with it. If I
    can't obtain the source, I can spend an hour or two studying the code,
    and I'll probably pick up the gist of the *how*.
    
    PLEASE PLEASE PLEASE ALWAYS COMMENT *WHY*. No matter how good I am, no
    amount of time I spend looking at your code will tell me what the hell
    the reason for its existence is. I can only guess the *why*.
    
    Lastly, commenting *where* is optional, but can be quite entertaining.

Exception:
  type: Language Construct
  description: |
    An exception is a value which can be "thrown" or "raised" at some point in the
    execution of a program. This act can be detected, and the exception
    "caught", by an exception handler installed at some previous point in the
    execution. Catching an exception causes execution to continue inside the
    handler, which can then decide what to do next. An uncaught exception
    generally causes the program to terminate.
  commentary: |
    Here is [[Cat's Eye Technologies]]' official position on exceptions:
    
    **Ask not where it makes sense to throw exceptions; ask where it makes
    sense to *catch* them.**
    
    If exceptions denote truly *exceptional* events, then by definition, you
    are not really *prepared* for them. You have to ask what your program
    can possibly do to recover from them. Out of memory? Syntax error in the
    configuration file? Database server down? Method doesn't exist? There's
    probably nothing that your program *can* do about these things, aside
    from giving up and notifying the person in charge that a problem has
    occurred.
    
    In this view, the main reason to use an exception, rather than, say,
    blithely dereferencing `NULL` and dumping core, is not because it is
    really a better solution per se; it's just that it's *prettier*.
    
    Not that that's bad, especially for commercial software! A newspaper
    article about a train wreck is a lot easier to handle psychologically
    than having it happen in your back yard. But my point is,
    [[Software Engineering|software-engineering]]-wise, the exception isn't really a
    *solution* to anything. (And, for internal tools, you probably actually
    *do* want to be at the scene of the train wreck — you'll need as many
    grisly details as possible in order to diagnose the problem.)
    
    An approach that takes this to the extreme is
    [[Erlang]]'s "let it crash" philosophy. Exceptions
    are often touted as a way to avoid having a bunch of "error-return
    checks" in your code. But if the problem is essentially irrecoverable,
    there's no sense having *any* error-return checks, even ones that are
    dressed up as exception handlers. They'll just lead to a bunch of
    seldom-taken code paths executing in hard-to-reason-about error-mode
    states which run the risk of corrupting data (by e.g. inserting invalid
    rows into a database.) Better by far to simply "let it crash" — log the
    error and the condition that led to it, and abort the program. If the
    program provides some kind of service, it can be restarted in a known
    state by an external monitor program.
    
    If, on the other hand, the event isn't truly exceptional, then the
    question to ask is "why is it being modelled as an exception?" Joel
    Spolsky raises [some excellent points in regards to this
    issue](http://www.joelonsoftware.com/items/2003/10/13.html) — multiple
    return values are often a more coherent way to cast the flow of control.
    The unique utility of exceptions is that they can perform *non-local*
    returns — control need not return to the immediate caller, it can skip
    back up to a procedure that called the procedure that called the
    procedure that called this one, if that's where the handler was
    installed.
    
    We believe that this property of exceptions should be taken into
    consideration when deciding upon an exception strategy: Will the callers
    of my caller ever care about this exception? When will the direct caller
    of my code *not* want to catch it? What benefit does this exception
    really have over an error-valued return value?
    
    [[Python]], for example, throws exceptions at the drop of a hat — when a
    value is not found while searching a list, for example. But likely it
    makes sense to catch that exception *always*, because *if you're
    searching for something, it probably means it might not be there*. And
    it makes sense to catch the exception *immediately after searching the
    list*, because *your callers probably shouldn't care that you're
    searching a list*. (If, in the future, you changed the implementation of
    your function so that it looked things up in a dictionary instead, a
    *different* exception would be thrown. Oi!)
    
    We feel that this is an injudicious use of exceptions, and that Python
    is, sadly, hardly a unique language design in this regard.

Closure:
  type: Language Construct
  description: |
    In [[Programming Language|programming languages]], a closure is an abstraction
    of an _expression_ in an _environment_; the expression may contain _free
    variables_ which are given meaning by the values _bound_ to them in the
    environment.
    
    That's how I use the term, anyway.  The general idea is that the closure
    "closes over" some data, capturing it.  Note, though, that this use of the word
    "closure" has barely any relationship to the mathematical notion of closure
    (which basically means to keep doing something over and over until there
    is nothing more that will change.)
    
    There are a few other concepts that are generally conflated with the idea
    of a closure.  One is the _function_: you can call it, it performs some
    computations, perhaps updates some data or accesses some other
    processes or devices as a side-effect, and perhaps returns some value.
    The other is the so-called _first-class value_:
    they can be stored in variables, passed as arguments to a function, and
    returned as the return value of a function.
    
    In practice, closures are almost always both of those things too.  But it's
    an arrangement of convenience rather than necessity; nothing in (my)
    definition of a closure strictly requires those two properties.
    
    You can have closures which are not first-class; maybe you can only
    return them from a function, but you can't pass them around.  I don't
    know why you'd want to have this restriction, but you could, and it
    wouldn't stop them from being closures.
    
    You can have closures which are not functions; for example, you could
    have a class or a module or some other construct close over some values,
    too.  In a weak sense, any
    object whose data is initialized via arguments to its constructor, is a
    closure.  It's perhaps not very useful to think of it that way, but it is
    also hard to make a coherent argument that it is *not* a closure.
    
    And of course, you can have a first-class function value which is still
    not a closure because it doesn't close over anything.  [[ANSI C|C]]'s
    function pointers fit this bill.
    
    I think one of the main reasons the conceptual ties between closures
    and first-class functions are so close is that, in the lambda calculus,
    the granddaddy of all functional languages, every function is a
    closure.
    
    Closures seem to be one of those things that are a bit troubling to
    many programming languages, though.
    
    LISP was the first language to promote functions as values, but it
    represented functions as lists and used dynamic binding to associate
    values with variables. This was a mess, and it took a long time for
    it to get better. Nowadays, [[Scheme]] has proper
    closures, and is a much more attractive choice overall (to me).
    
    [[Python]] 2's closures are limited to a single
    expression. This may be a syntactic problem rather than a semantic
    one, but it is still something of an annoyance.
    
    And then there's [[Ruby]], which... yeah, I'm pretty sure that
    among Ruby's 4 types of procedure, there are closures somewhere.
    
    [[Javascript]] has had closures from its beginnings — the problems
    there have been teaching them to web developers, who might not be
    experienced programmers who can appreciate their subtleties, and
    implementing them.  In the past they've been notorious for
    [leaking](http://www.jibbering.com/faq/faq_notes/closures.html#clMem).
    Partly this is a consequence of the difficulty of interpreting the
    definitions of the DOM — what should and what shouldn't stick around
    for how long.
    
    And that brings up the topic of memory management.
    Since the environment of a closure may contain variables local to the
    function in which it is created, and since the closure may be returned
    as a value from that function, it may *outlive* the local variables
    referred to by its environment. For this reason, the language (and by
    extension its implementations) must ensure that those values continue to
    exist for as long as the closure itself exists, for example by
    allocating them on the heap instead of on the call stack.    
    
    By overloading the `()` operator, it's possible to make closure-like
    objects even in [[C++]].  (pikhq has
    also demonstrated that with fancy enough tricks you can
    [also do this in C](https://github.com/pikhq/clambda-demo).)
    But if you try this, you'll
    soon appreciate why, in most languages, closures are garbage
    collected: if you have to explicitly reason about when the free
    variables will no longer be needed, you're not much better off from
    using function pointers.
    
    Many modern languages that didn't initially support closures are
    growing support for them because they're becoming more popular.
    You've always been able to make a closure in [[Java]] by instantiating
    an anonymous class with a single method on it and initializing the
    member variables of that class with the values you want that method
    to close over, but doing so is as awkward as this sentence, so more
    direct support for the idea has been proposed in later versions.
    [[PHP]] is also gaining support for
    [anonymous functions](http://php.net/manual/en/functions.anonymous.php).
    
    In contrast, [[Perl]] has had straight-up, no-nonsense closures from
    the beginnings of version 5, a pretty nice point in its favour.
