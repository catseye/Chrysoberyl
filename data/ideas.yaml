Boo-yah!:
  type: Programming Language
  genre: Esolang
  development-stage: idea
  authors:
  - Chris Pressey
  auspices:
  - Cat's Eye Technologies
  paradigms:
  - 2-dimensional
  no-specification: true
  summary: overlapping instructions in 2 dimensions
  inception-date: ca 1998
  description: |
    This thing's terminally undesigned.  I started thinking about
    it in the late nineties — possibly as early as 1998 — in Winnipeg.
    
    The challenge is to design a 2-dimensional language similar to [[Befunge-93]],
    except where each instruction is is composed, not of a single symbol, but of a 2×2 square of
    symbols.  As in Befunge, the IP should move at a rate of one cell per tick, and that
    means that each executed instruction must in general share two symbols with the
    previously executed instruction.  In other words, in *Boo*-yah!,
    instructions *overlap*.
    
    Symbols are drawn from the alphabet {`/`, `\\`}.  This two-symbol alphabet
    gives us 2^4 = 16 possible instructions.  4 of these instructions
    would be used to direct the flow of the IP like Befunge's `><^v`:
    
        \\  //  /\  \/
        //  \\  /\  \/
    
    That leaves 12 instructions to manipulate the state.
    
    One of the reasons that this has gone undesigned for so long is the difficulty in selecting
    a sufficiently "sweet" combination of instructions: one which will allow the instructions to be
    overlapped, while also having the instructions manipulate the state of the program in
    useful and interesting and non-trivial ways.
    
    It would be very tempting to just riff on [[brainfuck]] and have a tape,
    instructions that increment and decrement the current cell on that tape,
    and instructions that move back and forth on the tape.  But I think that's a bit boring.
    Ideally, each instruction would affect *several* different bits of state
    in the runtime model simultaneously, and it should be possible to come up with
    a series of instructions in which most, but not all, of those state changes
    have been cancelled out, leaving only the desired change in state.  Since this
    cancellation approach would naturally dovetail with overlapping, it would be a
    good fit for the language.


Faradaisical:
  type: Programming Language
  genre: Joke language
  development-stage: idea
  authors:
  - Chris Pressey
  auspices:
  - Cat's Eye Technologies
  paradigms:
  - Self-modifying
  no-specification: true
  summary: programmagnetic induction
  inception-date: ca 2009
  description: |
    Execution of instructions in one program creates a "programmagnetic field" which induces the execution of instructions
    in another nearby program.
    
    Now, I think that's a pretty good joke language, as is.  But it could maybe even be developed into something usable.
    Of course, it would ideally adhere to as many of the rules of electromagnetic induction as possible — cross product of
    the flux, and all that jazz.  Being able to
    wind a program around into a coil whose inductance can be measured in Turinghenries would be a bonus!  (Would it
    add ringing to a computation of the Ackermann function...?)


GI:
  type: Programming Language
  genre: Esolang
  development-stage: idea
  authors:
  - Chris Pressey
  auspices:
  - Cat's Eye Technologies
  paradigms:
  - Graph-rewriting
  no-specification: true
  summary: execution entails solving instances of GI
  inception-date: ca 2010
  description: |
    So we have a set of instructions, say two dozen or so.  So far, so good, right?
    
    Each of the instructions is identified by an undirected, unlabeled graph.  The program is a sequence
    of undirected graphs.  Each graph in the program is, in sequence, matched up with the
    instruction whose graph is isomorphic, and that instruction is executed.
    
    The result of this is that recognizing each instruction requires solving an instance of the
    <a href="http://en.wikipedia.org/wiki/Graph_isomorphism_problem" class="external">graph isomorphism problem</a>.
    This is an interesting problem, because (last I checked) no one knows whether this problem
    can be solved in polynomial time, nor whether it is NP-complete, so it has been given its own
    complexity class, **GI**.  The idea here is that the complexity of programs in the GI
    language needs to be expressed in terms of the **GI** complexity class.
    
    But there is a small problem with this design; namely, if all the graphs in the program
    are statically defined, an optimizing implementation could statically analyze the program,
    find matching instructions for each graph in the program beforehand, and cache them.  This
    would diminish the complexity of running the program to a finite number of instances of **GI**,
    plus whatever the "usual" complexity of the program is.
    
    To defeat that, we can basically force the graphs in the program to be dynamically
    defined: some subset of the instructions allows constructing a new graph (by creating an
    empty graph in some kind of "graph accumulator", adding nodes and edges, etc);
    newly assembled graphs can be executed via some kind of "eval" instruction; and
    newly assembled graphs *must* be executed, in a "quining" fashion,
    in order to enact repetition, a la [[Muriel]].
    
    Since new graphs would then be continually being generated, perhaps in
    chaotic and undecidable ways, the ability of an implementation to recognize and
    cache them would be severely limited, meaning that the complexity of a GI program
    really would need to be effectively measured in terms of **GI**.  For extra fun, some
    instruction could re-define the graphs which identify the instructions; while this
    certainly doesn't make it any easier to optimize a GI program, I don't think it's
    a strictly necessary step to defeat caching.
    
    (Oh, and each of the undirected, unlabeled graphs which represents an instruction
    could be termed a "dogtag".  Get it?  Get it?  "GI"?  Get it?)


Kig:
  type: Programming Language
  genre: Esolang
  development-stage: idea
  authors:
  - Chris Pressey
  auspices:
  - Cat's Eye Technologies
  paradigms:
  - 2-dimensional
  no-specification: true
  summary: five points collapse and expand
  inception-date: ca 2006
  description: |
    Kig was an idea I had while living in Vancouver
    for an automaton based on a 2-dimensional, orthogonal, integral, Cartesian grid
    containing only a set of five points.  The set of points would shrink until it could
    shrink no more, at which point it would explode, and begin to shrink again.
    The execution would be considered terminated once the pattern reached
    an obvious fixed point, i.e. when the points would cluster in the exact
    same way repeatedly before exploding.
    
    The shrinking occured in the following manner.  On each tick,
    pick the northwesternmost midpoint of two of the points, and call it
    the target.  (There is a
    [cute pigeonhole proof](http://www.cut-the-knot.org/pigeonhole/grid_mid.shtml)
    that, for 5 points with integral
    coordinates, such a midpoint with integral coordinates will always exist.)
    If the target is occupied by one other of the five points, stop — it's time to
    explode.  Otherwise, move the furthest, northwesternmost point to
    the target, and repeat.  Since there are still 5 points with integral
    coordinates, the midpoint property is preserved and the operation can be
    repeated as necessary.  We can also prove, fairly straightforwardly,
    that this shrinking procedure always terminates, i.e. always reaches
    the "it's time to explode" state.  (The "furthest, northwesternmost"
    condition is just to disambiguate, in the case that there are more than
    two points that have a midpoint.)
    
    Unfortunately, although I'm sure I had something in mind while I was
    riding the 99 B-Line home once, I can't for the life of me remember now
    how the explode phase was supposed to work.  Whatever it was, it
    would need to position the points far apart, based on their last
    shrink-phase configuration, in order to be interesting.  Extremely far
    apart, like exponentially so, would be best.  Even then, it's
    not clear if it would be possible to make this system Turing-complete.
    With 5 points, you do have 10 unbounded counters at your disposal —
    although your only real operation in the shrink-phase is something
    akin to division by two...


Paneer:
  type: Programming Language
  genre: Experimental language
  development-stage: idea
  authors:
  - Chris Pressey
  auspices:
  - Cat's Eye Technologies
  paradigms:
  - Meta-circular
  no-specification: true
  summary: comprehensive compositional language system
  inception-date: ca 2008
  description: |
    A self-modifying programming language which is "input-universal".
    That is, a programming language which can transform itself
    in a way similar to how [[Mascarpone]] transforms itself,
    but which also makes the guarantee that it can "turn itself
    into any other language," meaning that after a finite
    number of prefix symbols from the input program have been
    interpreted, the remaining symbols can be interpreted as
    a program in any other Turing-complete programming language.
    
    (Given a reasonable input alphabet, I suppose, and
    ignoring tedious and trivial details of encoding.)
    
    This is a matroiska language, because the input can be
    divided into distinct languages.  But it's possibly the
    most flexible possible matroiska language.
    
    I'm not 100% certain that Mascarpone doesn't already qualify.
    
    One part of this process — say, turning Mascarpone into
    Pascal — would be turning every symbol into a little state
    machine that scans and parses itself (when encountered in
    keyword context, or adds itself to a string constant if
    encountered between quotes.)


Poerhinekh:
  type: Programming Language
  genre: Esolang
  development-stage: idea
  authors:
  - Chris Pressey
  auspices:
  - Cat's Eye Technologies
  paradigms:
  - Meta-circular
  no-specification: true
  summary: rectangles within rectangles
  inception-date: 2009
  description: |
    Imagine a nominally graphical programming language, where the only
    program element is the lowly rectangle.  A program consists of an
    arrangement of rectangles; they may not overlap, but they may be nested
    inside other rectangles, and in this case they may butt up against the
    containing rectangle, so that they share a side.  Size of a rectangle
    does not matter, not even relative size, except insofar as to permit
    or disallow nesting.
    
    When a rectangle is nested within a larger containing
    rectangle, it can share 0, 1, 2, or 3 sides with the containing
    rectangle.  (For 3 sides, we consider the larger of the two
    inner areas to be the nested rectangle.)  When 0 sides are shared,
    there are no variations — position of the nested rectangle is
    immaterial.  When 1 side or 3 sides are shared, there are
    four variations (top, left, right, bottom).  When 2 sides are shared,
    there are four other variations (top-left, top-right, bottom-left,
    bottom-right).  All in all there are 4+4+4+1=13 possibilities for
    nesting.  This could map to 13 different instructions or program
    forms.  In addition, the nesting is a natural hierarchical pattern
    for program formation, so could represent block structure or
    precedence or such.


Psogumma:
  type: Programming Language
  genre: Esolang
  development-stage: idea
  authors:
  - Chris Pressey
  auspices:
  - Cat's Eye Technologies
  paradigms:
  - Meta-circular
  no-specification: true
  summary: grammar self-modifies to accomodate program
  inception-date: 2011
  description: |
    The Psogumma language provides a small, fixed grammar to start, possibly:
    
        Program ::= "+"* | "[" Program "]".
    
    However, when parsing a program, whenever there is a syntax error,
    the grammar is modified in a way which is pseudorandom, but always
    compatible with the input that caused the syntax error.  New productions
    may be introduced, or existing productions may be modified, to accomodate
    the input.  The semantics of the grammar modifications are similarly
    pseudorandomly generated at the moment they are applied.  The pseudorandom
    number generator is deterministic, starting with a fixed seed, but is
    continually engaged (being called each time an input symbol is consumed).
    
    The result is that all programs are parsable, and all programs have
    a well-defined meaning, although divining that meaning before parsing
    the program is at best an arduous task and at worst unpredictable (without
    having already parsed the program.)
